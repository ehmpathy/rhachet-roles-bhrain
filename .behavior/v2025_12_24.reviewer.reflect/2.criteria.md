# usecase.0 = briefs: rules knowledge

given('reviewer role is loaded')
  when('briefs are enumerated from src/roles/reviewer/briefs/')
    then('knowledge/rules.[article].md exists')
    then('article defines what rules are')
    then('article explains the relationship between rules and practices')
    then('article explains rules as materialized feedback patterns')
      sothat('agents understand the conceptual foundation of rules')
    then('knowledge/rules.structure.[article].md exists')
    then('article defines the rule file naming convention: rule.$directive.$topic.md')
    then('article explains directive taxonomy: forbid, avoid, prefer, require')
    then('article explains severity mapping: forbid/require=blocker, avoid/prefer=nitpick')
    then('article explains the practices/ directory structure')
      sothat('agents know how to organize rules by domain')
    then('knowledge/rules.content.[article].md exists')
    then('article defines two-section structure: # tldr and # deets')
    then('article defines # tldr section with:')
    then('  - .severity header (## severity: blocker|nitpick)')
    then('  - .what summary inline')
    then('  - .why rationale inline')
    then('article defines # deets section with optional:')
    then('  - .what = expanded summary')
    then('  - .why = expanded rationale')
    then('  - .where = scope/location')
    then('  - .when = applicability conditions')
    then('  - .how = rule detection and usage guidance')
    then('  - .note = caveats')
    then('  - .examples = positive and negative patterns')
    then('article defines separator between sections: ---\\n---\\n---')
      sothat('agents know how to write clear, actionable rules')
    then('knowledge/rules.citations.[article].md exists')
    then('article explains citations format with github URLs')
    then('article explains quote inclusion for evidence')
    then('article explains how citations enable provenance tracking')
      sothat('agents know how to trace rules back to their origin feedback')
    then('knowledge/rules.collocated.[article].md exists')
    then('article explains [demo] suffix for example files')
    then('article explains [ref] suffix for reference files')
    then('article explains [lesson] suffix for educational content')
    then('article explains colocation with related rule files')
      sothat('agents know how to add supporting documents to rules')

---

# usecase.1 = input: source directory

given('a --source dir is specified')
  when('the dir exists')
    then('all feedback files matching [feedback].*.[given]* pattern are enumerated')
      sothat('the skill knows which feedback to reflect upon')
  when('the dir contains nested subdirectories')
    then('feedback files are recursively enumerated from all subdirs')
      sothat('deeply nested feedback is not missed')
  when('the dir does not exist')
    then('the skill fails fast with a clear error')
      sothat('caller knows the source path is invalid')
  when('the dir contains zero feedback files')
    then('the skill fails fast with a clear error')
      sothat('caller knows there is no feedback to reflect upon')

---

# usecase.2 = input: target directory

given('a --target dir is specified')
  when('the dir exists')
    then('the dir is validated as a valid target for rule proposals')
      sothat('output can be written')
  when('the dir does not exist')
    then('the skill fails fast with a clear error')
    then('error suggests using --force to create the directory')
      sothat('caller explicitly confirms they expect a new target')
  when('the dir does not exist and --force is specified')
    then('the dir is created')
      sothat('caller can bootstrap a new rules directory intentionally')

---

# usecase.3 = step 1: generate citations

given('feedback files are enumerated from --source')
  when('citations are extracted')
    then('$DRAFT_DIR/citations.md is created')
    then('citations.md contains the full list of feedback file paths')
    then('each citation includes a valid remote github URL to the feedback file')
      sothat('the origin of each citation is permanently traceable')
  when('feedback files are on a git-tracked repo with remote')
    then('github URLs are constructed from the repo remote and file path')
      sothat('citations link back to the canonical source')
  when('feedback files are not git-tracked')
    then('the skill fails fast with a clear error')
      sothat('caller knows feedback must be in a git repo with remote')

---

# usecase.4 = step 1: propose pure rules

given('feedback has been cited')
  when('rules are proposed from feedback')
    then('$DRAFT_DIR/pure/ directory is created')
    then('each proposed rule is written as rule.$directive.$topic.md')
    then('directives are limited to: forbid, avoid, prefer, require')
    then('each rule file includes the exact quote of evidence')
    then('each rule file includes the github URL citation to its origin')
      sothat('every rule has traceable provenance')
  when('proposing rules')
    then('existing rules in $targetDir are NOT consulted')
    then('pure proposals are generated with fresh perspective')
      sothat('new insights are not tainted by existing rules')
  when('multiple feedback files reference similar guidance')
    then('the rule consolidates citations from all supporting feedback')
      sothat('rules are backed by comprehensive evidence')

---

# usecase.5 = step 2: create sync manifest

given('pure rules have been proposed')
  when('blending begins')
    then('a separate brain.repl:claude-code invocation is spawned')
    then('the brain receives the list of existing rules in $targetDir')
    then('the brain receives the list of pure proposals in $DRAFT_DIR/pure/')
      sothat('it can plan how to blend them')
  when('the brain analyzes the proposals vs existing rules')
    then('$DRAFT_DIR/manifest.json is created')
    then('manifest.json specifies the planned operation for each pure rule')
    then('operations are one of: OMIT, SET_CREATE, SET_UPDATE, SET_APPEND')
      sothat('the plan is explicit and auditable before execution')

---

# usecase.6 = step 2: sync operations

given('manifest.json has been created')
  when('operation is OMIT')
    then('the pure rule is not copied to sync')
    then('manifest.json records reason for omission')
      sothat('duplicates or irrelevant rules are skipped with justification')
  when('operation is SET_CREATE')
    then('the pure rule is copied to $DRAFT_DIR/sync/ with adapted path')
    then('the path matches the structure of $targetDir')
      sothat('new rules blend into existing taxonomy')
  when('operation is SET_UPDATE')
    then('the pure rule content is merged with the existing rule')
    then('merged content is written to $DRAFT_DIR/sync/')
      sothat('existing rules are enriched rather than replaced')
  when('operation is SET_APPEND')
    then('the pure rule is added as a supporting document')
    then('filename follows pattern rule.$directive.$topic.[demo|ref|lesson].$qualifier.md')
      sothat('supplementary material is collocated with the rule it supports')

---

# usecase.7 = mode: soft

given('--pull mode is specified')
  when('the brain is invoked')
    then('only file paths are passed in the prompt')
    then('the brain can open files as needed')
      sothat('context is loaded on demand for large feedback sets')

---

# usecase.8 = mode: hard

given('--push mode is specified')
  when('the brain is invoked')
    then('full file contents are injected into the prompt')
      sothat('the brain has all context pre-loaded')
  when('total tokens exceed 75% of context window')
    then('the skill fails fast before invoking the brain')
    then('error message states token count vs limit')
    then('error recommends reducing scope or switching to pull mode')
      sothat('caller avoids degraded quality from context rot')
  when('total tokens exceed 60% of context window')
    then('a warning is emitted about potential quality degradation')
    then('execution continues despite the warning')
      sothat('caller is informed but not blocked for moderate usage')

---

# usecase.9 = logging: input artifacts

given('the skill is invoked')
  when('feedback enumeration completes')
    then('.log/bhrain/reflect/$timestamp/input.args.json is written')
    then('input.args.json contains original input arguments')
    then('input.args.json contains enumerated feedback file paths')
    then('input.args.json contains stats on total tokens')
      sothat('the invocation is fully auditable')

---

# usecase.10 = logging: draft artifacts

given('step 1 completes')
  when('citations are extracted')
    then('.log/bhrain/reflect/$timestamp/step1.citations.md is written')
      sothat('citation extraction is logged')
  when('pure rules are proposed')
    then('.log/bhrain/reflect/$timestamp/step1.prompt.md is written')
    then('.log/bhrain/reflect/$timestamp/step1.response.json is written')
      sothat('the proposal prompt and response are preserved')

---

# usecase.11 = logging: blend artifacts

given('step 2 completes')
  when('manifest is created')
    then('.log/bhrain/reflect/$timestamp/step2.manifest.json is written')
      sothat('the blend plan is logged separately from $DRAFT_DIR')
  when('sync files are written')
    then('.log/bhrain/reflect/$timestamp/step2.prompt.md is written')
    then('.log/bhrain/reflect/$timestamp/step2.response.json is written')
      sothat('the blend prompt and response are preserved')

---

# usecase.12 = metrics: expected

given('the skill is invoked')
  when('feedback files are enumerated')
    then('metrics.expected is emitted to console')
    then('metrics.expected includes feedback file count')
    then('metrics.expected includes token estimate')
    then('metrics.expected includes context window percentage')
    then('metrics.expected includes approximate cost estimate')
      sothat('caller understands resource usage before brain invocation')
  when('metrics are computed')
    then('metrics.expected.json is written to log dir')
      sothat('expected metrics are persisted for comparison')

---

# usecase.13 = metrics: realized

given('brain invocation completes')
  when('step 1 brain returns')
    then('metrics.step1.realized.json is written to log dir')
    then('realized tokens (input, cache, output) are captured')
    then('realized costs are calculated and logged')
      sothat('actual usage for step 1 is tracked')
  when('step 2 brain returns')
    then('metrics.step2.realized.json is written to log dir')
    then('realized tokens and costs are captured for step 2')
      sothat('actual usage for step 2 is tracked')
  when('skill completes')
    then('metrics.realized summary is emitted to console')
    then('summary includes total tokens and costs across both steps')
      sothat('caller sees aggregate resource consumption')

---

# usecase.14 = output: draft directory structure

given('skill completes successfully')
  when('output is written')
    then('$targetDir/.draft/v$timestamp/ is created')
    then('$DRAFT_DIR/citations.md exists')
    then('$DRAFT_DIR/pure/ exists with proposed rules')
    then('$DRAFT_DIR/manifest.json exists with blend plan')
    then('$DRAFT_DIR/sync/ exists with blended rules')
      sothat('all artifacts are organized in the draft directory')

---

# usecase.15 = boundary: no source specified

given('no --source is specified')
  when('the skill is invoked')
    then('the skill fails fast with a clear error')
      sothat('caller knows source is required')

---

# usecase.16 = boundary: no target specified

given('no --target is specified')
  when('the skill is invoked')
    then('the skill fails fast with a clear error')
      sothat('caller knows target is required')

---

# usecase.17 = boundary: empty feedback

given('--source is specified')
  when('no files match [feedback].*.[given]* pattern')
    then('the skill fails fast with a clear error')
    then('error suggests checking the source path and feedback naming')
      sothat('caller knows why no feedback was found')

---

# usecase.18 = rule format: directive taxonomy

given('rules are proposed')
  when('directive is determined')
    then('forbid = blocker level violation when detected')
    then('require = blocker level, mandatory behavior')
    then('avoid = nitpick level, discouraged pattern')
    then('prefer = nitpick level, encouraged pattern')
      sothat('rule severity is clear from filename')

---

# usecase.19 = rule format: content structure

given('a rule file is written')
  when('content is formatted')
    then('rule includes .what = summary of the rule')
    then('rule includes .why = rationale for the rule')
    then('rule includes citation block with github URL and quote')
      sothat('rules are self-documenting and traceable')

---

# usecase.20 = shared code: domain.operations

given('skill is implemented')
  when('code is structured')
    then('common logic is lifted to domain.operations')
    then('review skill and reflect skill share enumeration logic')
    then('review skill and reflect skill share metrics computation')
    then('review skill and reflect skill share artifact writing')
      sothat('duplication is avoided and patterns are consistent')

---

# usecase.21 = brain: multi-step invocation

given('the skill runs both steps')
  when('step 1 brain is invoked')
    then('a fresh brain.repl:claude-code session handles proposal generation')
  when('step 2 brain is invoked')
    then('a separate brain.repl:claude-code session handles blending')
    then('step 2 does not share context with step 1')
      sothat('each step has clean context for its specific task')
