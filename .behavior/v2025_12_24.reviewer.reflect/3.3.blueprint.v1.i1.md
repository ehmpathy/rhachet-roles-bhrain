# blueprint.v1.i1 = reviewer.reflect skill

## overview

this blueprint describes the implementation of the `role=reviewer` `skill=reflect` feature, which extracts rules from user feedback files and proposes them into a target rules directory.

the skill operates in two distinct brain.repl:claude-code steps:
1. **propose pure rules** - generate fresh rule proposals, ignore existing rules
2. **blend proposals** - sync pure proposals with existing rules via manifest operations

---

## file structure

```
src/roles/reviewer/
├── briefs/
│   └── knowledge/
│       ├── rules.[article].md                    # what rules are
│       ├── rules.structure.[article].md          # name conventions + directory structure
│       ├── rules.content.[article].md            # .what/.why/.severity/.where/.when/.how/.note/.examples format
│       ├── rules.citations.[article].md          # github url citations
│       └── rules.collocated.[article].md         # [demo], [ref], [lesson] suffixes
│
├── skills/
│   ├── review/
│   │   └── review.ts                             # existing review skill (shares code)
│   │
│   └── reflect/
│       ├── reflect.ts                            # skill entrypoint
│       ├── reflect.sh                            # shell wrapper
│       ├── .test/
│       │   └── assets/                           # test fixtures
│       ├── reflect.unit.test.ts
│       └── reflect.integration.test.ts
```

---

## domain.operations

### shared operations (lifted from review skill)

```
src/domain.operations/
├── feedback/
│   ├── enumFeedbackFiles.ts                      # enumerate [feedback].*.[given]* files
│   └── enumFeedbackFiles.test.ts
│
├── metrics/
│   ├── computeMetricsExpected.ts                 # token estimates + cost
│   ├── computeMetricsRealized.ts                 # actual tokens + cost
│   └── *.test.ts
│
├── log/
│   ├── writeLogArtifact.ts                       # write to .log/bhrain/reflect/
│   └── *.test.ts
│
├── git/
│   ├── getGitRemoteUrl.ts                        # extract remote origin url
│   ├── genGitHubFileUrl.ts                       # construct github url from file path
│   └── *.test.ts
```

### reflect-specific operations

```
src/domain.operations/
├── reflect/
│   ├── step1/
│   │   ├── compileCitationsMarkdown.ts           # generate citations.md content
│   │   ├── compileReflectStep1Prompt.ts          # build step 1 brain prompt
│   │   └── *.test.ts
│   │
│   ├── step2/
│   │   ├── compileReflectStep2Prompt.ts          # build step 2 brain prompt
│   │   ├── parseManifestOperations.ts            # parse manifest.json
│   │   ├── executeManifestOperations.ts          # harness executes manifest
│   │   └── *.test.ts
│   │
│   ├── createDraftDirectory.ts                   # create $DRAFT_DIR structure
│   ├── validateSourceDirectory.ts                # validate --source exists + has feedback
│   ├── validateTargetDirectory.ts                # validate --target exists (or --force)
│   └── *.test.ts
```

---

## domain.objects

```
src/domain.objects/
├── ReflectMetrics.ts                             # metrics domain object
├── ReflectManifest.ts                            # manifest.json domain object
├── ManifestOperation.ts                          # OMIT | SET_CREATE | SET_UPDATE | SET_APPEND
└── RuleProposal.ts                               # proposed rule domain object
```

### ManifestOperation enum

```ts
export enum ManifestOperation {
  OMIT = 'OMIT',           // skip, not copied to sync
  SET_CREATE = 'SET_CREATE', // new rule, create in sync
  SET_UPDATE = 'SET_UPDATE', // merge with existing rule
  SET_APPEND = 'SET_APPEND', // add as support document
}
```

### ReflectManifest structure

```ts
interface ReflectManifest {
  timestamp: string;
  pureRules: Array<{
    path: string;                    // path in pure/
    operation: ManifestOperation;
    syncPath?: string;               // path in sync/ (if not OMIT)
    existingPath?: string;           // path in $targetDir (if UPDATE/APPEND)
    reason?: string;                 // justification for OMIT
  }>;
}
```

---

## output structure

### DRAFT_DIR layout

```
$targetDir/.draft/v$timestamp/
├── citations.md                     # full list of feedback citations
├── pure/                            # raw proposed rules
│   ├── rule.forbid.$topic1.md
│   ├── rule.prefer.$topic2.md
│   └── ...
├── manifest.json                    # blend plan
└── sync/                            # blended rules, match $targetDir structure
    ├── practices/
    │   └── $domain/
    │       ├── rule.forbid.$topic.md
    │       └── rule.forbid.$topic.[demo].$qualifier.md
    └── ...
```

### log directory layout

```
.log/bhrain/reflect/$timestamp/
├── input.args.json                  # original args + enumerated paths + token stats
├── step1.citations.md               # copy of citations.md
├── step1.prompt.md                  # prompt sent to brain
├── step1.response.json              # brain response
├── step2.manifest.json              # copy of manifest.json
├── step2.prompt.md                  # prompt sent to brain
├── step2.response.json              # brain response
├── metrics.expected.json            # pre-invocation estimates
├── metrics.step1.realized.json      # step 1 actual usage
├── metrics.step2.realized.json      # step 2 actual usage
└── metrics.realized.json            # aggregate summary
```

---

## skill interface

### cli arguments

```sh
npx rhachet run --role reviewer --skill reflect \
  --source $sourceDirToFindFeedbackToReflectUponIn \
  --target $targetDirToGiveProposalsOfRulesInto \
  [--mode soft|hard] \
  [--force]
```

| arg        | required | default | description                                |
| ---------- | -------- | ------- | ------------------------------------------ |
| `--source` | yes      | -       | directory to find feedback files in        |
| `--target` | yes      | -       | directory to emit rule proposals into      |
| `--mode`   | no       | `soft`  | `soft` = paths only, `hard` = full content |
| `--force`  | no       | `false` | create target directory if not exists      |

### programmatic interface

```ts
export const reflect = async (
  input: {
    source: string;
    target: string;
    mode?: 'soft' | 'hard';
    force?: boolean;
  },
  context: ReflectContext,
): Promise<ReflectResult>;
```

---

## execution flow

### phase 0: validation

```
1. validate --source exists
2. enumerate feedback files that match [feedback].*.[given]* pattern
3. fail fast if no feedback files found
4. validate --target exists (or create with --force)
5. validate feedback files are git-tracked with remote
6. compute metrics.expected
7. if mode=hard and tokens > 75% context: fail fast
8. if mode=hard and tokens > 60% context: warn
9. write input.args.json to log
10. emit metrics.expected to console
```

### phase 1: propose pure rules

```
1. generate github urls for each feedback file
2. compile citations.md with all citations
3. write citations.md to $DRAFT_DIR
4. compile step 1 prompt (mode determines content injection)
5. spawn brain.repl:claude-code with step 1 prompt
6. brain writes rules to $DRAFT_DIR/pure/
7. write step1.prompt.md and step1.response.json to log
8. write metrics.step1.realized.json to log
```

### phase 2: blend proposals

```
1. enumerate existing rules in $targetDir
2. enumerate pure proposals in $DRAFT_DIR/pure/
3. compile step 2 prompt with both lists
4. spawn fresh claude-code with step 2 prompt
5. brain writes manifest.json to $DRAFT_DIR
6. write step2.prompt.md and step2.response.json to log
7. write metrics.step2.realized.json to log
8. harness parses manifest.json and executes operations:
   - OMIT: skip (log reason)
   - SET_CREATE: copy to $DRAFT_DIR/sync/ with adapted path
   - SET_UPDATE: merge content and write to $DRAFT_DIR/sync/
   - SET_APPEND: add as support doc with [demo|ref|lesson].$qualifier.md suffix
```

### phase 3: finalize

```
1. compute aggregate metrics.realized
2. write metrics.realized.json to log
3. emit metrics.realized summary to console
4. return result with paths to draft artifacts
```

---

## brain prompts

### step 1 prompt structure (propose)

```md
# objective
propose rules from feedback citations

# citations
$citations.md content (or paths in pull mode)

# instructions
- propose rules as rule.$directive.$topic.md files
- include .what, .why, citation block with github url + quote
- do not consult existing rules
- consolidate multiple feedback citations into single rule where applicable
- write to $DRAFT_DIR/pure/

# output
write rule files to $DRAFT_DIR/pure/
```

### step 2 prompt structure (blend)

```md
# objective
blend pure proposals with existing rules

# existing rules
$existingRulePaths (or content in push mode)

# pure proposals
$pureProposalPaths (or content in push mode)

# instructions
1. analyze each pure proposal vs existing rules
2. write manifest.json with planned operations:
   - OMIT: duplicate or irrelevant (include reason)
   - SET_CREATE: new rule, adapt path to match $targetDir structure
   - SET_UPDATE: merge content with existing rule
   - SET_APPEND: add as collocated support document

# output
manifest.json to $DRAFT_DIR (harness will execute operations)
```

---

## rule file format

### filename pattern

```
rule.$directive.$topic.md                           # primary rule
rule.$directive.$topic.[demo].$qualifier.md         # example/demo
rule.$directive.$topic.[ref].$qualifier.md          # reference material
rule.$directive.$topic.[lesson].$qualifier.md       # educational content
```

### content structure

```md
# tldr

## severity: blocker|nitpick

[.what summary]

[.why rationale]

---
---
---

# deets

## .what (optional)
[expanded summary of the rule]

## .why (optional)
[expanded rationale for the rule]

## .where (optional)
[scope or location where this rule applies]

## .when (optional)
[conditions when this rule applies]

## .how (optional)
[rule detection and usage guidance]

## .note (optional)
[caveats, edge cases, special considerations]

## .examples (optional)

### positive
[example of correct usage]

### negative
[example of violation]

---

## .citations

> [exact quote from feedback]

source: [github url to feedback file]
```

### directive taxonomy

| directive | severity | description         |
| --------- | -------- | ------------------- |
| `forbid`  | blocker  | must not do this    |
| `require` | blocker  | must do this        |
| `avoid`   | nitpick  | discouraged pattern |
| `prefer`  | nitpick  | encouraged pattern  |

---

## test strategy

### test assets structure

```
src/roles/reviewer/skills/reflect/.test/
├── assets/
│   ├── example.feedback/
│   │   ├── typescript-quality/                    # code feedback repo
│   │   │   ├── .behavior/
│   │   │   │   └── v2025_01_01.feature/
│   │   │   │       ├── [feedback].v1.[given].by_human.md
│   │   │   │       ├── [feedback].v2.[given].by_human.md
│   │   │   │       └── [feedback].v3.[given].by_human.md
│   │   │   └── .git/                              # initialized git repo
│   │   │
│   │   └── prose-author/                          # prose feedback repo
│   │       ├── .behavior/
│   │       │   └── v2025_01_01.chapter-review/
│   │       │       ├── [feedback].v1.[given].by_human.md
│   │       │       └── [feedback].v2.[given].by_human.md
│   │       └── .git/                              # initialized git repo
│   │
│   └── example.target/
│       └── practices/                             # existing rules to blend with
│           └── code.prod/
│               └── rule.require.tests.md
```

### unit tests

```
- enumFeedbackFiles: pattern match, recursion
- genGitHubFileUrl: url construction from remote + path
- compileCitationsMarkdown: format verification
- parseManifestOperations: json parse + validation
- executeManifestOperations: OMIT, SET_CREATE, SET_UPDATE, SET_APPEND
- validateSourceDirectory: existence + file checks
- validateTargetDirectory: existence + --force handle
```

### integration tests

```ts
const ASSETS_CODE_FEEDBACK = path.join(__dirname, '.test/assets/example.feedback/typescript-quality');
const ASSETS_PROSE_FEEDBACK = path.join(__dirname, '.test/assets/example.feedback/prose-author');
const ASSETS_TARGET = path.join(__dirname, '.test/assets/example.target');

/**
 * setup git repo with remote for feedback tests
 */
const setupFeedbackRepo = async (sourceAssets: string): Promise<{ repoDir: string }> => {
  const repoDir = path.join(os.tmpdir(), `reflect-test-${Date.now()}`);
  await fs.cp(sourceAssets, repoDir, { recursive: true });
  execSync('git init', { cwd: repoDir });
  execSync('git add .', { cwd: repoDir });
  execSync('git commit -m "initial"', { cwd: repoDir, env: GIT_ENV });
  execSync('git remote add origin https://github.com/test/repo.git', { cwd: repoDir });
  return { repoDir };
};
```

```
given('[case1] no source specified')
  when('[t0] reflect is called')
    then('throws BadRequestError about missing --source')

given('[case2] source directory does not exist')
  when('[t0] reflect is called')
    then('throws BadRequestError about invalid source path')

given('[case3] source contains zero feedback files')
  when('[t0] reflect is called')
    then('throws BadRequestError about no feedback found')

given('[case4] target directory does not exist')
  when('[t0] reflect executed without --force')
    then('throws BadRequestError that suggests --force')
  when('[t1] reflect executed with --force')
    then('creates target directory')
    then('writes draft artifacts to $DRAFT_DIR')

given('[case5] typescript-quality feedback repo')
  when('[t0] before any changes')
    then('feedback glob matches 3 files')
    then('all feedback files are git-tracked')

  when('[t1] stepReflect in pull mode')
    then('citations.md contains github urls for all feedback')
    then('pure/ contains proposed rules with correct format')
    then('each rule has # tldr and # deets sections')
    then('each rule has .citations with github urls')
    then('manifest.json specifies operations for each pure rule')
    then('sync/ contains blended rules')
    then('metrics.expected contains token estimates')
    then('metrics.realized contains actual usage')
    then('log artifacts written to .log/bhrain/reflect/')

  when('[t2] stepReflect in push mode')
    then('full content injected into prompts')
    then('produces same structure as pull mode')

given('[case6] prose-author feedback repo')
  when('[t0] before any changes')
    then('feedback glob matches 2 files')

  when('[t1] stepReflect with existing target rules')
    then('manifest.json includes SET_UPDATE for overlaps')
    then('manifest.json includes SET_CREATE for new rules')
    then('manifest.json includes OMIT for duplicates with reason')
    then('sync/ structure mirrors target practices/ hierarchy')

given('[case7] push mode token limits')
  when('[t0] tokens exceed 75% context window')
    then('fails fast with token count vs limit in error')
  when('[t1] tokens exceed 60% context window')
    then('emits warning to console')
    then('continues execution')

given('[case8] feedback files not git-tracked')
  when('[t0] reflect is called')
    then('throws BadRequestError about git requirement')

given('[case9] feedback files have no remote')
  when('[t0] reflect is called')
    then('throws BadRequestError about remote requirement')
```

### acceptance tests

```
given('[case1] real feedback from example typescript repo')
  when('[t0] reflect executed end-to-end')
    then('produces valid rule proposals')
    then('citations link to valid github urls')
    then('rule content follows # tldr / # deets structure')
    then('manifest operations are reasonable')

given('[case2] real feedback from example prose repo')
  when('[t0] reflect executed end-to-end')
    then('produces prose-relevant rule proposals')
    then('rules blend correctly with existing target')
```

---

## implementation phases

### phase 1: foundation

- [ ] create briefs in `src/roles/reviewer/briefs/knowledge/`
- [ ] create domain.objects (ReflectInput, ReflectManifest, etc.)
- [ ] create validation operations (validateSourceDirectory, validateTargetDirectory)
- [ ] create git operations (getGitRemoteUrl, genGitHubFileUrl)

### phase 2: step 1 implementation

- [ ] lift enumFeedbackFiles from review skill to domain.operations
- [ ] create compileCitationsMarkdown operation
- [ ] create compileReflectStep1Prompt operation
- [ ] create createDraftDirectory operation
- [ ] implement step 1 flow with brain.repl:claude-code

### phase 3: step 2 implementation

- [ ] create compileReflectStep2Prompt operation
- [ ] create parseManifestOperations operation
- [ ] implement step 2 flow with brain.repl:claude-code
- [ ] implement manifest operation execution

### phase 4: metrics + log

- [ ] lift metrics operations from review skill
- [ ] lift log operations from review skill
- [ ] implement metrics.expected + metrics.realized
- [ ] implement log artifact write

### phase 5: integration

- [ ] create reflect.ts skill entrypoint
- [ ] create reflect.sh shell wrapper
- [ ] write unit tests
- [ ] write integration tests
- [ ] write acceptance tests

---

## dependencies

### existing packages

- `domain-objects` - domain model
- `helpful-errors` - fail-fast errors
- `type-fns` - type utilities

### cli tools

- `claude` - claude-code cli for brain invocation (same as review.ts)

### shared code from review skill

- invokeClaudeCode pattern
- metrics computation
- log artifact write
- mode handle (soft/hard)

---

## open questions

1. should sync/ preserve the exact structure of $targetDir?
   - current design: yes, mirror the practices/ hierarchy
   - this enables direct comparison and potential cp operations

2. how to handle conflict rule proposals (same topic, different directives)?
   - decision: flag as dupe in manifest, let human resolve
