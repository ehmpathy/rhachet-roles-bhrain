# lats-pattern (language agent tree search)

## .what

an advanced agent framework that combines tree-of-thoughts with monte carlo tree search (MCTS), using external feedback and learned value functions to guide exploration of action sequences.

## .why

LATS addresses limitations of both linear agents (no backtracking) and static tree search (no learning). by incorporating MCTS principles — selection, expansion, simulation, backpropagation — LATS can learn from failed trajectories and allocate search effort efficiently toward promising paths.

## dependsOn

- `tree-of-thoughts` — tree structure for exploration
- `agentic-loop` — action execution
- `reflexion-pattern` — learning from feedback

## mcts components in LATS

| component | implementation |
|-----------|----------------|
| selection | UCB1-guided node choice |
| expansion | llm generates candidate actions |
| simulation | execute action, observe result |
| backpropagation | update values based on outcome |

## pattern structure

```
        [Root State]
             │
    ┌────────┼────────┐
    │        │        │
 [A:0.6]  [B:0.8]  [C:0.4]  ← UCB1 selects B
             │
    ┌────────┼────────┐
    │        │        │
 [B1:0.7] [B2:0.9] [B3:0.5]  ← expand B, simulate
             │
          [success]
             │
         backpropagate +reward
```

## benchmark performance

| benchmark | LATS performance |
|-----------|-----------------|
| HotPotQA | state-of-the-art among agent methods |
| WebShop | improved over ReAct/Reflexion |
| Programming | higher solve rates with search |

## key innovations over ToT

| aspect | ToT | LATS |
|--------|-----|------|
| exploration | static heuristic | learned UCB1 |
| feedback | evaluation only | environment + reflection |
| memory | none | experience buffer |
| replanning | from scratch | informed by history |

## computational cost

LATS is more expensive than simpler methods:
- multiple simulation trajectories
- value function updates
- but more sample-efficient than random exploration

## when to use

- complex multi-step tasks
- sparse reward signals
- when backtracking is valuable
- sufficient compute budget

## sources

- [Language Agent Tree Search (LATS)](https://arxiv.org/abs/2310.04406) — original paper (ICML 2024)
- [Understanding LLM Agent Planning Survey](https://arxiv.org/abs/2402.02716) — positions LATS in taxonomy
