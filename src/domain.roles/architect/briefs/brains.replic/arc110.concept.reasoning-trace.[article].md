# reasoning-trace

## .what

explicit intermediate reasoning steps that an llm produces before generating a final answer, making its thought process visible and improving accuracy on complex tasks.

## .why

reasoning traces transform black-box generation into interpretable problem-solving. by externalizing intermediate steps, the llm can break down complex problems, catch errors in its reasoning, and provide explanations that humans can verify. this is the foundation for chain-of-thought and related techniques.

## dependsOn

- `llm` — generates the reasoning trace
- `context-window` — traces consume tokens

## key characteristics

- **intermediate**: produced before final answer
- **natural language**: typically readable text
- **step-by-step**: decomposed reasoning
- **self-documenting**: explains the llm's approach

## example

```
Question: What is 23 × 17?

Reasoning trace:
- I need to multiply 23 by 17
- 23 × 17 = 23 × (10 + 7)
- = 23 × 10 + 23 × 7
- = 230 + 161
- = 391

Answer: 391
```

## elicitation methods

| method | technique |
|--------|-----------|
| zero-shot | "Let's think step by step" |
| few-shot | provide example traces |
| trained | fine-tune on trace datasets |
| scratchpad | dedicated trace output space |

## benefits

- improved accuracy on reasoning tasks
- reduced hallucination
- debuggable/auditable outputs
- enables self-correction

## sources

- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903) — seminal paper
- [Scratchpads](https://arxiv.org/abs/2112.00114) — intermediate computation
- [Extended Thinking](https://www.anthropic.com/news/visible-extended-thinking) — claude's thinking mode
