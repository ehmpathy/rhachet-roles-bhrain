# self-consistency

## .what

a decoding strategy that samples multiple reasoning paths from the llm and selects the final answer by majority vote, leveraging the intuition that correct reasoning is more likely to converge on the same answer.

## .why

self-consistency exploits the stochastic nature of llm generation as a feature rather than a bug. different reasoning paths may make different mistakes, but correct paths tend to agree on the final answer. by sampling multiple times and voting, we reduce the impact of individual reasoning errors.

## dependsOn

- `reasoning-trace` — each sample produces a trace
- `llm` — generates multiple samples

## pattern structure

```
Question: What is the capital of Australia?

Sample 1: "Australia is in Oceania. Sydney is the largest city.
           But the capital is Canberra." → Canberra

Sample 2: "Australia's government is in Canberra, which was
           purpose-built as the capital." → Canberra

Sample 3: "The largest city is Sydney, which might be the
           capital." → Sydney

Majority vote: Canberra (2/3)
Final answer: Canberra
```

## key characteristics

- **embarrassingly parallel**: all samples independent
- **temperature > 0**: requires stochastic sampling
- **answer extraction**: must identify final answer in each trace
- **voting mechanism**: typically majority, can be weighted

## benchmark performance

| benchmark | improvement over greedy CoT |
|-----------|---------------------------|
| arithmetic | +17.9% (GSM8K) |
| commonsense | +11.0% (CommonsenseQA) |
| symbolic | significant gains |

## parameters

| parameter | effect |
|-----------|--------|
| num_samples | more samples = higher accuracy, higher cost |
| temperature | higher = more diverse samples |
| voting method | majority, weighted, etc. |

## cost analysis

self-consistency is more expensive than single-path CoT:
- linear cost increase with sample count
- typically 5-40 samples used
- parallelizable (latency ≈ single sample if concurrent)

## limitations

- requires extractable final answers
- expensive for long generations
- doesn't help if all paths fail similarly

## sources

- [Self-Consistency Improves Chain of Thought Reasoning](https://arxiv.org/abs/2203.11171) — original paper
- [Reasoning with LM Prompting Survey](https://github.com/zjunlp/Prompt4ReasoningPapers) — comparison with other methods
